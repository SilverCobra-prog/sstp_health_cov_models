{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP/dwlTqlkezAf9P19niQ2R"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C52loq63Q3ze","executionInfo":{"status":"ok","timestamp":1689825022481,"user_tz":240,"elapsed":1172629,"user":{"displayName":"Raghav Aggarwal","userId":"04371493702700305700"}},"outputId":"93e42322-dd75-4c94-b410-d0c5bbea68d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","169/169 [==============================] - 507s 3s/step - loss: 0.5956 - accuracy: 0.6625\n","Epoch 2/5\n","169/169 [==============================] - 502s 3s/step - loss: 0.4832 - accuracy: 0.7749\n","Epoch 3/5\n","169/169 [==============================] - 496s 3s/step - loss: 0.3995 - accuracy: 0.8325\n","Epoch 4/5\n","169/169 [==============================] - 493s 3s/step - loss: 0.3373 - accuracy: 0.8639\n","Epoch 5/5\n","169/169 [==============================] - 490s 3s/step - loss: 0.2761 - accuracy: 0.9004\n","43/43 [==============================] - 12s 246ms/step\n","Accuracy: 0.7823179791976226\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Embedding, LSTM, Dense\n","from keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# Load your dataset from a CSV file\n","df = pd.read_csv('/content/human_annotations_same - human_annotations_same.csv')\n","\n","# Preprocess the text data\n","texts = df['text']\n","labels = df['human_label1']\n","\n","# Tokenize the text data\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(texts)\n","sequences = tokenizer.texts_to_sequences(texts)\n","\n","# Pad the sequences to ensure uniform length\n","max_sequence_length = max(len(sequence) for sequence in sequences)\n","padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n","\n","\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n","\n","# Build the RNN model\n","vocab_size = len(tokenizer.word_index) + 1  # Add 1 for the padding token\n","embedding_dim = 50  # Dimensionality of the word embeddings\n","hidden_units = 8  # Number of LSTM units\n","model = Sequential()\n","model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length))\n","model.add(LSTM(units=hidden_units))\n","model.add(Dense(units=1, activation='sigmoid'))\n","\n","# Compile and train the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","model.fit(X_train, y_train, epochs=5, batch_size=32)\n","\n","# Make predictions on the testing set\n","y_pred = model.predict(X_test)\n","y_pred = np.round(y_pred).flatten()\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n"]},{"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix\n","\n","print(classification_report(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vXgCYlPnscU6","executionInfo":{"status":"ok","timestamp":1689141818835,"user_tz":300,"elapsed":133,"user":{"displayName":"Raghav Aggarwal","userId":"04371493702700305700"}},"outputId":"e25adb14-b704-4685-89f8-53a9c38bbbe2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.71      0.78      0.74       850\n","           1       0.54      0.45      0.49       496\n","\n","    accuracy                           0.66      1346\n","   macro avg       0.63      0.62      0.62      1346\n","weighted avg       0.65      0.66      0.65      1346\n","\n"]}]}]}